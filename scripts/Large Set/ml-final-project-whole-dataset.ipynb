{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.models import vgg16\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:44:20.559180Z","iopub.execute_input":"2022-05-20T12:44:20.559513Z","iopub.status.idle":"2022-05-20T12:44:23.005244Z","shell.execute_reply.started":"2022-05-20T12:44:20.559430Z","shell.execute_reply":"2022-05-20T12:44:23.004145Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(0)\nnp.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:44:23.007508Z","iopub.execute_input":"2022-05-20T12:44:23.007882Z","iopub.status.idle":"2022-05-20T12:44:23.017922Z","shell.execute_reply.started":"2022-05-20T12:44:23.007835Z","shell.execute_reply":"2022-05-20T12:44:23.016896Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Reading Data","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/happy-whale-train-csv/train.csv\")\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:44:25.247630Z","iopub.execute_input":"2022-05-20T12:44:25.247972Z","iopub.status.idle":"2022-05-20T12:44:25.387355Z","shell.execute_reply.started":"2022-05-20T12:44:25.247942Z","shell.execute_reply":"2022-05-20T12:44:25.386362Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Fix some typos\ndata.species.replace({\"globis\": \"short_finned_pilot_whale\",\n                          \"pilot_whale\": \"short_finned_pilot_whale\",\n                          \"kiler_whale\": \"killer_whale\",\n                          \"bottlenose_dolpin\": \"bottlenose_dolphin\"}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:44:27.242445Z","iopub.execute_input":"2022-05-20T12:44:27.242767Z","iopub.status.idle":"2022-05-20T12:44:27.264917Z","shell.execute_reply.started":"2022-05-20T12:44:27.242734Z","shell.execute_reply":"2022-05-20T12:44:27.263944Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data['species'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:44:29.760414Z","iopub.execute_input":"2022-05-20T12:44:29.761493Z","iopub.status.idle":"2022-05-20T12:44:29.778944Z","shell.execute_reply.started":"2022-05-20T12:44:29.761430Z","shell.execute_reply":"2022-05-20T12:44:29.777949Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def data_clean_and_load(data):\n    # Select the 6 species\n    # Dolphin: Bottlenose Dolphin, Dusky Dolphin, Spinner Dolphin\n    # Whales: Beluga, Blue Whale, Killer Whale\n    data_cleaned = pd.get_dummies(data[['image', 'species']], columns = ['species'])[['image',\n                                                                                      'species_bottlenose_dolphin',\n                                                                                      'species_beluga',\n                                                                                      'species_blue_whale',\n                                                                                      'species_killer_whale',\n                                                                                      'species_dusky_dolphin',\n                                                                                      'species_spinner_dolphin']]\n    # Drop the instances that don't belong to the 5 species\n    drop_index = data_cleaned[data_cleaned.drop(columns = 'image').sum(axis = 1) != 1].index\n    data_cleaned = data_cleaned.drop(drop_index)\n    \n    # Read all images and convert them into np.array\n    X = []\n    for img_name in data_cleaned['image']:\n        image = Image.open('../input/jpeg-happywhale-128x128/train_images-128-128/train_images-128-128/' + img_name)\n        X.append(np.asarray(image))\n    X = np.stack(X, axis = 0).reshape(-1, 3, 128, 128)\n    \n    # Target\n    Y = data.drop(columns = ['image', 'individual_id']).drop(drop_index).to_numpy().flatten()\n    return X, Y\n    \nX, Y = data_clean_and_load(data)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:44:31.729788Z","iopub.execute_input":"2022-05-20T12:44:31.730173Z","iopub.status.idle":"2022-05-20T12:46:32.696243Z","shell.execute_reply.started":"2022-05-20T12:44:31.730133Z","shell.execute_reply":"2022-05-20T12:46:32.695120Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-19T20:22:50.042888Z","iopub.execute_input":"2022-05-19T20:22:50.043821Z","iopub.status.idle":"2022-05-19T20:22:50.050421Z","shell.execute_reply.started":"2022-05-19T20:22:50.04376Z","shell.execute_reply":"2022-05-19T20:22:50.049529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:49:16.923430Z","iopub.execute_input":"2022-05-20T12:49:16.923831Z","iopub.status.idle":"2022-05-20T12:49:18.307603Z","shell.execute_reply.started":"2022-05-20T12:49:16.923796Z","shell.execute_reply":"2022-05-20T12:49:18.306605Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom collections import Counter\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:49:19.519101Z","iopub.execute_input":"2022-05-20T12:49:19.520047Z","iopub.status.idle":"2022-05-20T12:49:19.979108Z","shell.execute_reply.started":"2022-05-20T12:49:19.519952Z","shell.execute_reply":"2022-05-20T12:49:19.978116Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"enc2 = OneHotEncoder()\nY_train = enc2.fit_transform(Y_train[:,np.newaxis]).toarray()\nY_val = enc2.fit_transform(Y_val[:,np.newaxis]).toarray()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:49:20.577567Z","iopub.execute_input":"2022-05-20T12:49:20.578431Z","iopub.status.idle":"2022-05-20T12:49:20.600000Z","shell.execute_reply.started":"2022-05-20T12:49:20.578398Z","shell.execute_reply":"2022-05-20T12:49:20.598932Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train_ss, X_val_ss, Y_train_ss, Y_val_ss = train_test_split(X_val, Y_val, test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T04:39:10.866215Z","iopub.execute_input":"2022-05-19T04:39:10.866913Z","iopub.status.idle":"2022-05-19T04:39:10.933727Z","shell.execute_reply.started":"2022-05-19T04:39:10.866873Z","shell.execute_reply":"2022-05-19T04:39:10.932983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Oversample","metadata":{}},{"cell_type":"code","source":"original = X_train.shape\n\nsampler = SMOTE(random_state = 0)\nX_resampled, Y_resampled = sampler.fit_resample(X_train.reshape((X_train.shape[0],-1)), Y_train)\nX_resampled = X_resampled.reshape((-1, original[1], original[2], original[3]))","metadata":{"execution":{"iopub.execute_input":"2022-05-15T10:13:01.982714Z","iopub.status.busy":"2022-05-15T10:13:01.982415Z","iopub.status.idle":"2022-05-15T10:14:07.792356Z","shell.execute_reply":"2022-05-15T10:14:07.791317Z","shell.execute_reply.started":"2022-05-15T10:13:01.982681Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_imb(Y):\n    counter = Counter(Y)\n    for k,v in counter.items():\n        per = v / len(Y) * 100\n        print('Class=%s, n=%d (%.3f%%)' % (k, v, per))","metadata":{"execution":{"iopub.execute_input":"2022-05-15T10:14:07.795421Z","iopub.status.busy":"2022-05-15T10:14:07.795084Z","iopub.status.idle":"2022-05-15T10:14:07.810297Z","shell.execute_reply":"2022-05-15T10:14:07.809176Z","shell.execute_reply.started":"2022-05-15T10:14:07.795378Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_imb(Y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc = OneHotEncoder()\nY_resampled = enc.fit_transform(Y_resampled[:,np.newaxis]).toarray()","metadata":{"execution":{"iopub.execute_input":"2022-05-15T10:14:07.812302Z","iopub.status.busy":"2022-05-15T10:14:07.811939Z","iopub.status.idle":"2022-05-15T10:14:07.845021Z","shell.execute_reply":"2022-05-15T10:14:07.844164Z","shell.execute_reply.started":"2022-05-15T10:14:07.812265Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline Models","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ndef model_train_and_score(model, X, Y, X_val, Y_val):\n    return np.mean(cross_val_score(model, X, Y))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import linear_model as LM\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.execute_input":"2022-05-15T10:10:27.242305Z","iopub.status.busy":"2022-05-15T10:10:27.241991Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dim = 128*128*3\n\ntrain_x_ss = X_train_ss.reshape(-1,dim)\ntrain_y_ss = np.argmax(Y_train_ss, axis = 1)\nval_x_ss = X_val_ss.reshape(-1,dim)\nval_y_ss = np.argmax(Y_val_ss, axis = 1)\n\nsampler = SMOTE(random_state = 0)\nX_ss_resampled, Y_ss_resampled = sampler.fit_resample(train_x_ss, train_y_ss)","metadata":{"execution":{"iopub.execute_input":"2022-05-15T10:10:27.242305Z","iopub.status.busy":"2022-05-15T10:10:27.241991Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_imb(train_y_ss)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n          Without SMOTE.       With SMOTE\nKNN:    0.6761318681318681  0.5780756114505837\n \nLR:     0.7373289007910857  0.5664851619786406\n\nDT:     0.6213721180780004  0.5246923831236833\n","metadata":{}},{"cell_type":"code","source":"KNN = KNeighborsClassifier(n_neighbors = 5)\nLogisticReg = LM.LogisticRegression(penalty = 'none',\n                                   tol = 1e-3,\n                                   solver = 'lbfgs',\n                                   max_iter = 50)\nDT = DecisionTreeClassifier(max_depth = 10, random_state = 0)\n\nfor model in [KNN, LogisticReg, DT]:\n    print('\\n =================================')\n    print('Without SMOTE:')\n    print(model_train_and_score(model, train_x_ss, train_y_ss, val_x_ss, val_y_ss))\n    print('\\nWith SMOTE:')\n    print(model_train_and_score(model, X_ss_resampled, Y_ss_resampled, val_x_ss, val_y_ss))\n    print('\\n')","metadata":{"execution":{"iopub.execute_input":"2022-05-15T10:10:27.242305Z","iopub.status.busy":"2022-05-15T10:10:27.241991Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loader","metadata":{}},{"cell_type":"code","source":"class whale_dolphin(Dataset):\n    def __init__(self, X, Y):\n        self.imgs = X\n        self.labels = np.argmax(Y, axis = 1)\n        self.transforms = transforms.Compose([\n            transforms.ToTensor()\n        ])\n\n    def __len__(self):\n        return len(self.imgs)\n\n    def __getitem__(self, index):\n        img_data = self.imgs[index]\n        img_data = self.transforms(img_data).view(3,128,128)\n        img_label = self.labels[index]\n#         print(type(img_label))\n#         img_label = torch.tensor(img_label, dtype=torch.float, requires_grad=True)\n        return img_data, img_label","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:49:27.199233Z","iopub.execute_input":"2022-05-20T12:49:27.199663Z","iopub.status.idle":"2022-05-20T12:49:27.216504Z","shell.execute_reply.started":"2022-05-20T12:49:27.199600Z","shell.execute_reply":"2022-05-20T12:49:27.214566Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_dataset = whale_dolphin(X_train, Y_train)\n#train_dataset_rs = whale_dolphin(X_resampled, Y_resampled)\nval_dataset = whale_dolphin(X_val, Y_val)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:49:28.380377Z","iopub.execute_input":"2022-05-20T12:49:28.380867Z","iopub.status.idle":"2022-05-20T12:49:28.387069Z","shell.execute_reply.started":"2022-05-20T12:49:28.380813Z","shell.execute_reply":"2022-05-20T12:49:28.386046Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\nval_dataloader = DataLoader(val_dataset, batch_size = 64, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:49:29.323486Z","iopub.execute_input":"2022-05-20T12:49:29.324521Z","iopub.status.idle":"2022-05-20T12:49:29.331663Z","shell.execute_reply.started":"2022-05-20T12:49:29.324455Z","shell.execute_reply":"2022-05-20T12:49:29.330287Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for data, label in val_dataloader:\n    print(data.shape)\n    print(label)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:35:19.067588Z","iopub.execute_input":"2022-05-19T16:35:19.068364Z","iopub.status.idle":"2022-05-19T16:35:19.09201Z","shell.execute_reply.started":"2022-05-19T16:35:19.068304Z","shell.execute_reply":"2022-05-19T16:35:19.091334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NN training","metadata":{}},{"cell_type":"code","source":"def train(model, device, n_epochs, optimizer, criterion, train_dataloader, val_dataloader):\n    model.to(device)\n    val_acc_list = []\n    out_dir = \"/\"\n    train_loss = []\n    val_loss = []\n    if not os.path.exists(out_dir):\n        os.makedirs(out_dir)\n    for epoch in range(n_epochs):\n        print(f\"\\nEpoch {epoch + 1}\")\n        model.train()\n        sum_loss = 0.0\n        v_loss_sum = 0.0\n        correct = 0.0\n        total = 0.0\n        for batch_idx, (images, labels) in enumerate(train_dataloader):\n            length = len(train_dataloader)\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)  # torch.size([batch_size, num_class])\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            sum_loss += loss.item()\n            _, predicted = torch.max(outputs.data, dim=1)\n            total += labels.size(0)\n            correct += predicted.eq(labels.data).cpu().sum()\n            # iteration = batch_idx + 1 + epoch * length\n            # t_los = sum_loss / (batch_idx + 1)\n            # acc = round(100. * correct / total, 3)\n            # print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '\n                  #% (epoch + 1, (batch_idx + 1 + epoch * length), sum_loss / (batch_idx + 1), 100. * correct / total))\n        train_loss.append(sum_loss / len(train_dataloader))\n        \n        print(\"Waiting Val...\")\n        with torch.no_grad():\n            correct = 0.0\n            total = 0.0\n            for batch_idx, (images, labels) in enumerate(val_dataloader):\n                model.eval()\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, dim=1)\n                v_loss_sum += criterion(outputs,labels).item()\n                total += labels.size(0)\n                correct += (predicted == labels).sum()\n            \n            val_loss.append(v_loss_sum / len(val_dataloader))\n            print('Val\\'s ac is: %.3f%%' % (100 * correct / total))\n\n            acc_val = 100. * correct / total\n            val_acc_list.append(acc_val)\n        \n    return train_loss, val_loss\n#         torch.save(model.state_dict(), out_dir + \"last.pt\")\n#         if acc_val == max(val_acc_list):\n#             torch.save(model.state_dict(), out_dir + \"best.pt\")\n#             print(f\"save epoch {epoch} model\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:49:31.194430Z","iopub.execute_input":"2022-05-20T12:49:31.195300Z","iopub.status.idle":"2022-05-20T12:49:31.212300Z","shell.execute_reply.started":"2022-05-20T12:49:31.195253Z","shell.execute_reply":"2022-05-20T12:49:31.211112Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## ResNet","metadata":{}},{"cell_type":"code","source":"class BottleNeck(nn.Module):\n    \"\"\"\n    BottleNeck block for the ResNet-50\n    1x1, 3x3, 1x1 Three convolution layers\n    \"\"\"\n    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n        super().__init__()\n        self.expansion = 4\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)  # No Size Change\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride,\n                               padding=1)  # if stride=2，half size of the input, if =1, don't change\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)  # No Size Change\n        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n        self.relu = nn.ReLU()\n        self.identity_downsample = identity_downsample\n\n    def forward(self, x):\n        identity = x\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n\n        # identity shortcut\n        x = x + identity\n        x = self.relu(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-19T04:39:34.638259Z","iopub.execute_input":"2022-05-19T04:39:34.638837Z","iopub.status.idle":"2022-05-19T04:39:34.648264Z","shell.execute_reply.started":"2022-05-19T04:39:34.638798Z","shell.execute_reply":"2022-05-19T04:39:34.647596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet50(nn.Module):\n    def __init__(self, bottleneck, layers, image_channels, class_nums):\n        super().__init__()\n        # initialize the in_channels after the first max pool layer\n        self.in_channels = 64\n\n        # conv1\n        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n\n        # Res net bottleneck layers conv2, conv3, conv4, conv5\n        # conv2\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.conv2 = self._make_layer(bottleneck, layers[0], out_channels=64, stride=1)\n        # conv3\n        self.conv3 = self._make_layer(bottleneck, layers[1], out_channels=128, stride=2)\n        # conv4\n        self.conv4 = self._make_layer(bottleneck, layers[2], out_channels=256, stride=2)\n        # conv5\n        self.conv5 = self._make_layer(bottleneck, layers[3], out_channels=512, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * 4, class_nums)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.maxpool(x)\n\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n\n        x = self.avgpool(x)\n        x = x.reshape(x.shape[0], -1)  # reshape the four-d tensor to 2-d matrix\n        x = self.fc(x)\n\n        return x\n\n    def _make_layer(self, bottleneck, block_nums, out_channels, stride):\n        identity_downsample = None\n        layers = []\n        block_minus = 0\n        if stride != 1 or self.in_channels != out_channels * 4:\n            identity_downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels * 4, kernel_size=1, stride=stride),\n                nn.BatchNorm2d(out_channels * 4)\n            )\n            block_minus = 1\n        layers.append(bottleneck(self.in_channels, out_channels, identity_downsample, stride=stride))\n        self.in_channels = out_channels * 4\n\n        for i in range(block_nums - block_minus):\n            layers.append(bottleneck(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T04:39:35.468526Z","iopub.execute_input":"2022-05-19T04:39:35.468775Z","iopub.status.idle":"2022-05-19T04:39:35.483526Z","shell.execute_reply.started":"2022-05-19T04:39:35.468745Z","shell.execute_reply":"2022-05-19T04:39:35.482701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1 = ResNet50(BottleNeck, [3, 4, 6, 3], 3, 6)\ncriterion = nn.CrossEntropyLoss()\nlearning_rate = 1e-4\noptimizer = torch.optim.Adam(model_1.parameters(), lr=learning_rate)\ntrain(model_1, 'cuda', 20, optimizer, criterion, train_dataloader, val_dataloader)","metadata":{"execution":{"iopub.execute_input":"2022-05-15T08:31:58.177048Z","iopub.status.busy":"2022-05-15T08:31:58.176456Z","iopub.status.idle":"2022-05-15T09:20:38.881965Z","shell.execute_reply":"2022-05-15T09:20:38.881111Z","shell.execute_reply.started":"2022-05-15T08:31:58.177006Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ResNet50 Without SMOTE\nresnet = ResNet50(BottleNeck, [3, 4, 6, 3], 3, 6)\ncriterion = nn.CrossEntropyLoss()\nlearning_rate = 1e-4\noptimizer = torch.optim.Adam(resnet.parameters(), lr=learning_rate)\ntrain(resnet, 'cuda', 20, optimizer, criterion, train_dataloader, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T04:39:47.654323Z","iopub.execute_input":"2022-05-19T04:39:47.654605Z","iopub.status.idle":"2022-05-19T05:03:30.207654Z","shell.execute_reply.started":"2022-05-19T04:39:47.654576Z","shell.execute_reply":"2022-05-19T05:03:30.206876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VGG16","metadata":{}},{"cell_type":"code","source":"# VGG16 Without SMOTE\nvgg_model = vgg16(pretrained = True)\n\nfor param in vgg_model.parameters():\n    param.requires_grad = False\n\nvgg_model.classifier.add_module('7', nn.Linear(1000, 6))\nprint(vgg_model)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T17:14:10.297104Z","iopub.execute_input":"2022-05-19T17:14:10.297359Z","iopub.status.idle":"2022-05-19T17:14:11.821535Z","shell.execute_reply.started":"2022-05-19T17:14:10.297332Z","shell.execute_reply":"2022-05-19T17:14:11.816541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nlearning_rate = 1e-4\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, vgg_model.parameters()), lr=learning_rate)\ntrain_loss_vgg, val_loss_vgg = train(vgg_model, 'cuda', 50, optimizer, criterion, train_dataloader, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T17:14:12.565752Z","iopub.execute_input":"2022-05-19T17:14:12.566229Z","iopub.status.idle":"2022-05-19T17:51:27.619487Z","shell.execute_reply.started":"2022-05-19T17:14:12.566192Z","shell.execute_reply":"2022-05-19T17:51:27.618743Z"},"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot\n\npyplot.plot(np.arange(50), train_loss_vgg, color = 'blue')\npyplot.plot(np.arange(50), val_loss_vgg, color = 'red')","metadata":{"execution":{"iopub.status.busy":"2022-05-19T17:53:26.869518Z","iopub.execute_input":"2022-05-19T17:53:26.870204Z","iopub.status.idle":"2022-05-19T17:53:27.054241Z","shell.execute_reply.started":"2022-05-19T17:53:26.870164Z","shell.execute_reply":"2022-05-19T17:53:27.053558Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AlexNet","metadata":{}},{"cell_type":"code","source":"from torchvision.models import alexnet\nalex_model = alexnet(pretrained = True)\n\nfor param in alex_model.parameters():\n    param.requires_grad = False\n\nalex_model.classifier.add_module('7', nn.Linear(1000, 6))\nprint(alex_model)\n\ncriterion = nn.CrossEntropyLoss()\nlearning_rate = 1e-4\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, alex_model.parameters()), lr=learning_rate)\ntrain_loss_alex, val_loss_alex = train(alex_model, 'cuda', 50, optimizer, criterion, train_dataloader, val_dataloader)","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-19T18:00:17.185289Z","iopub.execute_input":"2022-05-19T18:00:17.185559Z","iopub.status.idle":"2022-05-19T18:07:05.280816Z","shell.execute_reply.started":"2022-05-19T18:00:17.185532Z","shell.execute_reply":"2022-05-19T18:07:05.280053Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot\n\npyplot.plot(np.arange(37), train_loss_alex, color = 'blue')\npyplot.plot(np.arange(37), val_loss_alex, color = 'red')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:01:31.553905Z","iopub.execute_input":"2022-05-20T13:01:31.554558Z","iopub.status.idle":"2022-05-20T13:01:31.576544Z","shell.execute_reply.started":"2022-05-20T13:01:31.554523Z","shell.execute_reply":"2022-05-20T13:01:31.575064Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import alexnet\nalex_model = alexnet(pretrained = False)\n\nalex_model.classifier.add_module('7', nn.Linear(1000, 6))\nprint(alex_model)\n\ncriterion = nn.CrossEntropyLoss()\nlearning_rate = 1e-4\noptimizer = torch.optim.Adam(alex_model.parameters(), lr=learning_rate)\ntrain_loss_alex, val_loss_alex = train(alex_model, 'cuda', 50, optimizer, criterion, train_dataloader, val_dataloader)","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-20T12:50:20.460618Z","iopub.execute_input":"2022-05-20T12:50:20.460955Z","iopub.status.idle":"2022-05-20T13:01:03.926501Z","shell.execute_reply.started":"2022-05-20T12:50:20.460923Z","shell.execute_reply":"2022-05-20T13:01:03.925176Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## ResNet","metadata":{}},{"cell_type":"code","source":"from torchvision.models import resnet50\nresnet_model = resnet50(pretrained = True)\n\nfor param in resnet_model.parameters():\n    param.requires_grad = False\n    \nresnet_model.fc = nn.Linear(2048,6)\n\nprint(resnet_model)\n\ncriterion = nn.CrossEntropyLoss()\nlearning_rate = 1e-4\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, resnet_model.parameters()), lr=learning_rate)\ntrain_loss_res, val_loss_res = train(resnet_model, 'cuda', 50, optimizer, criterion, train_dataloader, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T18:17:33.192292Z","iopub.execute_input":"2022-05-19T18:17:33.192555Z","iopub.status.idle":"2022-05-19T18:38:11.190924Z","shell.execute_reply.started":"2022-05-19T18:17:33.192527Z","shell.execute_reply":"2022-05-19T18:38:11.189098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pyplot.plot(np.arange(50), train_loss_res, color = 'blue')\npyplot.plot(np.arange(50), val_loss_res, color = 'red')","metadata":{"execution":{"iopub.status.busy":"2022-05-19T18:38:52.284964Z","iopub.execute_input":"2022-05-19T18:38:52.285211Z","iopub.status.idle":"2022-05-19T18:38:52.472953Z","shell.execute_reply.started":"2022-05-19T18:38:52.285185Z","shell.execute_reply":"2022-05-19T18:38:52.472179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import resnet50\nresnet_model = resnet50(pretrained = False)\n\n    \nresnet_model.fc = nn.Linear(2048,6)\n\nprint(resnet_model)\n\ncriterion = nn.CrossEntropyLoss()\nlearning_rate = 1e-4\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, resnet_model.parameters()), lr=learning_rate)\ntrain_loss_res, val_loss_res = train(resnet_model, 'cuda', 50, optimizer, criterion, train_dataloader, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:01:55.883519Z","iopub.execute_input":"2022-05-20T13:01:55.883837Z","iopub.status.idle":"2022-05-20T13:57:28.166073Z","shell.execute_reply.started":"2022-05-20T13:01:55.883807Z","shell.execute_reply":"2022-05-20T13:57:28.165027Z"},"trusted":true},"execution_count":17,"outputs":[]}]}